PRACTICAL 2 : 
--------------------------------------------------------

PRACTICAL NO. 02-RETRIVAL MODELS
AIM: Implement the vector space model with TFIDF weighting and cosine similarity
Code: 
import re
import math
from collections import Counter

def tokenize(text):
    """Convert text to lowercase and extract alphanumeric tokens."""
    return re.findall(r'\w+', text.lower())

def build_vector(tokens, vocab):
    """Create a term-frequency vector based on a vocabulary."""
    freq = Counter(tokens)
    return [freq.get(term, 0) for term in vocab]

def cosine_similarity(vec1, vec2):
    """Calculate cosine similarity between two vectors."""
    dot_product = sum(a * b for a, b in zip(vec1, vec2))
    norm1 = math.sqrt(sum(a * a for a in vec1))
    norm2 = math.sqrt(sum(b * b for b in vec2))
    if norm1 == 0 or norm2 == 0:
        return 0.0
    return dot_product / (norm1 * norm2)

def main():
    # Step 0: Input documents and query
    n = int(input("Enter number of documents: "))
    documents = []
    for i in range(n):
        documents.append(input(f"Enter document {i+1}: "))
    query = input("Enter your query: ")

    # Tokenize documents and query
    doc_tokens = [tokenize(doc) for doc in documents]
    query_tokens = tokenize(query)

    # Step 1: Display documents
    print("\nStep 1: Documents")
    for i, doc in enumerate(documents, 1):
        print(f"Document {i}: {doc}")

    # Step 2: Build vocabulary
    vocab_set = set()
    for tokens in doc_tokens:
        vocab_set.update(tokens)
    print("\nStep 2: Vocabulary")
    print(vocab_set)

    # Step 3: Sort vocabulary
    sorted_vocab = sorted(vocab_set)
    print("\nStep 3: Sorted Vocabulary")
    print(sorted_vocab)

    # Step 4: Create vectors
    doc_vectors = [build_vector(tokens, sorted_vocab) for tokens in doc_tokens]
    query_vector = build_vector(query_tokens, sorted_vocab)

    print("\nStep 4: Vector Space Representation")
    print(f"Sorted Vocabulary: {sorted_vocab}")
    print(f"Query Vector: {query_vector}")
    for i, vec in enumerate(doc_vectors, 1):
        print(f"Document {i} Vector: {vec}")

    # Step 5: Calculate cosine similarities
    similarities = []
    print("\nStep 5: Cosine Similarities")
    for i, doc_vec in enumerate(doc_vectors, 1):
        similarity = cosine_similarity(query_vector, doc_vec)
        similarities.append(similarity)
        print(f"Query vs Document {i}: {similarity:.4f}")

    # Step 6: Display final similarities
    print("\nStep 6: Ranking")
    for i, sim in enumerate(similarities, 1):
        print(f"Document {i}: {sim:.4f}")

if __name__ == "__main__":
    main()
